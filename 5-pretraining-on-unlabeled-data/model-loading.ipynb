{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n",
      "Output: tensor([[15496,    11,   314,   716,  2018, 44808, 18415, 44949, 42175, 39141,\n",
      "         24002,  8617, 38769, 50013, 43976, 34796,  5987, 11250, 37495, 44278,\n",
      "         46700,  7098,  1360, 41217, 46771, 21229,  2370,  9335, 21979, 29147,\n",
      "         33362, 14366, 42812,  3492]])\n",
      "Output length: 34\n",
      "Decoded text: Hello, I am connect00007UCTalamigrate Turing Fut provisionsigrateduvian Dos bowlsessorconfigjavascript consonFILrazilgy Twice paperback squeeze evidence maskCat Cruise hospitality peoples cassette ready\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken\n",
    "from chapter4 import GPTModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "Load the model and optimizer in a new Python session or Jupyter notebook file and continue pretraining it for one more epoch using the train_model_simple function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embed): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256, # was previously 1024\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(123)\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0., top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # getting the predictions\n",
    "        with torch.no_grad():\n",
    "            logits=model(idx_cond)\n",
    "\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        # taking only the last logits since that's what we want!\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # filtering logits with top_k sampling:\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                condition=logits < min_val,\n",
    "                input=torch.tensor(float('-inf')).to(logits.device),\n",
    "                other=logits\n",
    "            )\n",
    "        \n",
    "        # applying temperature scaling\n",
    "        if temperature > 0:\n",
    "            logits = logits / temperature\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probabilities, num_samples=1)\n",
    "        \n",
    "        # applying greedy next-token generation\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs for the inputted text (i.e. 'start_context'):\n",
      "tensor([[6109, 3626, 6100,  345]])\n",
      "\n",
      "Generated token IDs based on the inputted text and context length:\n",
      "tensor([[ 6109,  3626,  6100,   345,   760,   284,   670,   319,   438, 15464,\n",
      "            11,   355,   340,   547]])\n",
      "\n",
      "Output text via decoding the generated token IDs:\n",
      "Every effort moves you know to work on--forming, as it were\n"
     ]
    }
   ],
   "source": [
    "# utility functions for text to token ID and vice versa conversions\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # adding batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flatten = token_ids.squeeze(0) # removing batch dimension\n",
    "    return tokenizer.decode(flatten.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "# starting text gets fed to text_to_token_ids for encoding, and that gets fed to generate_text_simple to\n",
    "# generate the remaining tokens\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "decoded_and_generated = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "print(f\"Token IDs for the inputted text (i.e. 'start_context'):\\n{text_to_token_ids(start_context, tokenizer)}\\n\\nGenerated token IDs based on the inputted text and context length:\\n{token_ids}\\n\\nOutput text via decoding the generated token IDs:\\n{decoded_and_generated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18431 2048\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "print(len(train_data), len(val_data))\n",
    "print((len(train_data) + len(val_data)) - len(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chapter2 import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "----------------------------------\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"----------------------------------\\n\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# this computes the loss for a single batch\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = F.cross_entropy(\n",
    "        logits.flatten(0, 1),\n",
    "        target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "# this calculates the loss across all the batches in a given data loader\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0 # starting point\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader) # iterates over all batches if no fixed num_batches specified\n",
    "    else:\n",
    "        # if num_batches > len(data_loader), reduce the num_batches to match len(data_loader) so that it still works\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches # averaging the loss over all the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9526826739311218\n",
      "Validation loss: 6.2875776290893555\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval() # disabling dropout for stable reproducible results\n",
    "    with torch.no_grad(): # disables gradient tracking since this is eval\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate(\n",
    "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "\n",
    "# ============= model training function â†“ ===============\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
    "                       num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # epoch loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        # batch loop\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # zero grad\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # loss calculation on current batch\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "\n",
    "            # backprop to calculate loss gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update the weights based on these loss gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation (prints the things that happen one-by-one during the training)\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"\"\"Ep {epoch+1} (Step {global_step:06d}): \n",
    "                      Train loss {train_loss:.3f}, \n",
    "                      Val loss {val_loss:.3f}\"\"\")\n",
    "            \n",
    "            # printing a sample text after each token\n",
    "            generate_and_print_sample(\n",
    "                model, tokenizer, device, start_context\n",
    "            )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): \n",
      "                      Train loss 0.705, \n",
      "                      Val loss 6.363\n",
      "It is a privilege, one of my surprise, one of the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\"  \"Oh, he had dropped his painting, the donkey. \"strongest,\" she began\n",
      "It is a privilege, that mighty up-stream stroke. The mere outline of the frame called up all Gisburn's past!  \"Oh, a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "It is a privilege, that mighty up-stream stroke. The mere outline of the tips of a self-confident moustache, I felt to see a degree he had the window-curtains, I saw that, my eye fell on a small picture\n",
      "It is a privilege, that mighty up-stream stroke. The mere outline of the tips of a self-confident moustache, I felt to see a degree he had the window-curtains, as I turned, my eye fell on a small picture\n",
      "It is a privilege, I meant to do the picture for nothing--I told Mrs. Stroud so when she began to stammer something about her poverty. I remember getting off a prodigious phrase about the honour being _mine_--oh, I was.\n",
      "Ep 1 (Step 000005): \n",
      "                      Train loss 0.534, \n",
      "                      Val loss 6.414\n",
      "It is a privilege sunburnt cheeks furrowed by a smile that lifted the tips of a self-confident moustache, I felt to see a degree he had the same quality as his pictures--the quality of Jack's \"There were days when I\n",
      "It is a privilege sunburnt cheeks furrowed by a smile that lifted the tips of a self-confident moustache, I felt to see a degree he had the same quality as his pictures--the quality of Jack's \"strongest,\" as his\n",
      "It is a privilege sunburnt cheeks furrowed by a smile that lifted the tips of a self-confident moustache, I felt to see a degree he had the same quality as his pictures--the quality of looking cleverer than he was.\n",
      "It is a privilege sunburnt cheeks furrowed by a smile that lifted the tips of a self-confident moustache, I felt to what a degree he had the same quality as his pictures--the quality of looking cleverer than he was.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()\n",
    "num_epochs=1\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs,\n",
    "    eval_freq=5, eval_iter=5, start_context=\"It is a privilege\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\" )\n",
    "    \n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not much change here.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
